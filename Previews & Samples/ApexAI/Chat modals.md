# Chat Models

Welcome to the comprehensive guide for chat models available with `Apexify.js`. This README covers all the chat models you can use, categorized by provider and type.

## üöÄ Available Chat Models

### 1. **Hercai (Herc) Models**

- **v3**: Versatile and high-performance model for general-purpose chat.
- **v3-32k**: Extended context model for handling larger conversations.
- **turbo**: Optimized for faster responses and efficiency.
- **turbo-16k**: Extended context version of the turbo model.
- **gemini**: Advanced model with improved understanding and responses.
- **llama3-70b**: Large model with extensive capabilities.
- **llama3-8b**: Smaller variant for more specific applications.
- **mixtral-8x7b**: Special model for mixed-task handling.
- **gemma-7b**: High-performance model for diverse interactions.
- **gemma2-9b**: Enhanced version of the Gemma model.

### 2. **Groq Models**

- **gemma-7b-it**: Italian variant of the Gemma model.
- **gemma2-9b-it**: Italian variant of the Gemma2 model.
- **llama3-groq-70b-8192-tool-use-preview**: Tool-usage preview model with extensive capabilities.
- **llama3-groq-8b-8192-tool-use-preview**: Smaller tool-usage preview model.
- **llama-3.1-70b-versatile**: Versatile model with extensive features.
- **llama-3.1-8b-instant**: Instant response model with a focus on speed.
- **llama-guard-3-8b**: Model with enhanced safety features.
- **llama3-70b-8192**: Large model for deep and comprehensive conversations.
- **llama3-8b-8192**: Smaller variant for focused interactions.
- **mixtral-8x7b-32768**: Extended context model for mixed tasks.

### 3. **RSN Models**

- **bard**: General-purpose chat model with creative capabilities.
- **bing**: Search-focused model with integrated web results.
- **codellama**: Model specialized for coding-related queries.
- **gemini**: Similar to the Hercules version with unique features.
- **llama**: General-purpose model with balanced performance.
- **mixtral**: Versatile model for various applications.
- **openchat**: Model focused on open-domain conversations.
- **v4**: Latest generation model with advanced features.

### 4. **Electron Hub Chat Models**

- **o1-mini**: Lightweight model optimized for basic interactions.
- **o1-preview**: Preview model for early-stage testing of advanced features.
- **claude-3.5-sonnet-200k**: High-capacity model with extended context support.
- **claude-3-sonnet-200k**: Similar to Claude-3.5, but with optimizations for speed.
- **gpt-4-turbo**: Optimized version of GPT-4 with enhanced performance.
- **command-r-plus**: Enhanced model for command-based tasks.
- **command-r**: Standard command-response model for task handling.
- **gpt-4**: Standard GPT-4 model with full capabilities.
- **chatgpt-4o-latest**: Latest optimized version of GPT-4o for improved speed and accuracy.

-# Note: There is a default apiKey but limited. To get your own apikey join:
[![ElectronHub](https://api.weblutions.com/discord/invite/83XcjD8vgW/)](https://discord.gg/83XcjD8vgW)

### 5. **Other Chat Models**

- **apexai**: Custom model for specialized applications.
- **facebook_ai**: Model developed by Facebook for diverse interactions.
- **yi_34b**: Model with a focus on advanced conversational capabilities.
- **starChat**: Model for engaging and dynamic conversations.

### 6. **FresedGPT Models**

- **gpt-4o**: Specialized version of GPT-4 for optimized performance.

-# Note: There is a default apiKey but limited. To get your own apikey join:
[![FresedGPT](https://api.weblutions.com/discord/invite/94qUZWhwFE/)](https://discord.gg/94qUZWhwFE)  


### 7. **Gemini Models**

- **gemini-pro**: Enhanced version of the Gemini model with advanced features.
- **gemini-flash**: High-speed variant of the Gemini model optimized for fast responses.

## üõ†Ô∏è Installation

To use any of these chat models, you need to install **Apexify.js**. Follow the installation instructions below:

### npm

```bash
npm install apexify.js
```

### pnpm

```bash
pnpm add apexify.js
```

### yarn

```bash
yarn add apexify.js
```

### bun

```bash
bun add apexify.js
```

---

Feel free to explore the models and integrate them into your applications. For further assistance or if you have any questions, reach out via Discord!